"""
ì°¸ê³  íŒŒì¼: Upstage API ì§ì ‘ í˜¸ì¶œ í´ë¼ì´ì–¸íŠ¸

ì¶œì²˜: ê¸°ì¡´ í”„ë¡œì íŠ¸ (ì‚¬ìš©ì ì œê³µ)
ì°¸ê³  ëª©ì : Upstage API í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„ ì°¸ê³ 

ì£¼ìš” ì°¨ì´ì  ì˜ˆìƒ:
1. ì´ëª¨ì§€ ì‚¬ìš©: ì°¸ê³  íŒŒì¼ì—ëŠ” ì´ëª¨ì§€(ğŸ“„, ğŸ“¡, âœ… ë“±)ê°€ ìˆìœ¼ë‚˜, í˜„ì¬ í”„ë¡œì íŠ¸ëŠ” ì´ëª¨ì§€ ì‚¬ìš© ê¸ˆì§€ â†’ `[INFO]`, `[ERROR]` í˜•ì‹ìœ¼ë¡œ ë³€ê²½ í•„ìš”
2. ë¡œê¹… í˜•ì‹: ì°¸ê³  íŒŒì¼ì€ ì¼ë°˜ ë¡œê¹…, í˜„ì¬ í”„ë¡œì íŠ¸ëŠ” `[INFO]`, `[ERROR]` í˜•ì‹ ì‚¬ìš©
3. PyPDF2 vs pypdf: ì°¸ê³  íŒŒì¼ì€ PyPDF2 ì‚¬ìš©, í˜„ì¬ í”„ë¡œì íŠ¸ëŠ” pypdf ì‚¬ìš© â†’ ë³€ê²½ í•„ìš”
4. ì„¤ì • ê´€ë¦¬: ì°¸ê³  íŒŒì¼ì€ `api_key`ë¥¼ ì§ì ‘ ë°›ì§€ë§Œ, í˜„ì¬ í”„ë¡œì íŠ¸ëŠ” `Settings` í´ë˜ìŠ¤ ì‚¬ìš©
5. ë³€ìˆ˜ëª…/í•¨ìˆ˜ëª…: í˜„ì¬ í”„ë¡œì íŠ¸ ê·œì¹™ì— ë§ê²Œ Align í•„ìš”

Python requestsë¥¼ ì‚¬ìš©í•˜ì—¬ Upstage Document Parse APIë¥¼ ì§ì ‘ í˜¸ì¶œí•©ë‹ˆë‹¤.
100í˜ì´ì§€ ì´ˆê³¼ ì‹œ ìë™ìœ¼ë¡œ ë¶„í•  íŒŒì‹±í•©ë‹ˆë‹¤.
"""

import requests
from typing import Dict, Any, List
from pathlib import Path
import logging
import time
from PyPDF2 import PdfReader, PdfWriter
import tempfile

logger = logging.getLogger(__name__)


class UpstageAPIClient:
    """Upstage Document Parse API í´ë¼ì´ì–¸íŠ¸"""

    MAX_PAGES_PER_REQUEST = 100  # API í˜ì´ì§€ ì œí•œ

    def __init__(self, api_key: str):
        """
        Args:
            api_key: Upstage API í‚¤
        """
        self.api_key = api_key
        self.url = "https://api.upstage.ai/v1/document-digitization"

    def parse_pdf(self, pdf_path: str, retries: int = 3) -> Dict[str, Any]:
        """
        PDF íŒŒì‹± (100í˜ì´ì§€ ì´ˆê³¼ ì‹œ ìë™ ë¶„í• )

        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            retries: ì¬ì‹œë„ íšŸìˆ˜

        Returns:
            {
                "api": "2.0",
                "model": "document-parse-250618",
                "usage": {"pages": total_pages},
                "content": {"html": "...", "markdown": "", "text": ""},
                "elements": [...],
                "metadata": {
                    "split_parsing": True/False,
                    "total_chunks": N
                }
            }
        """
        # PDF í˜ì´ì§€ ìˆ˜ í™•ì¸
        total_pages = self._get_pdf_page_count(pdf_path)
        logger.info(f"ğŸ“„ PDF has {total_pages} pages")

        if total_pages <= self.MAX_PAGES_PER_REQUEST:
            # 100í˜ì´ì§€ ì´í•˜: í•œ ë²ˆì— íŒŒì‹±
            logger.info(f"ğŸ“¡ Single request parsing ({total_pages} pages)")
            result = self._parse_single_pdf(pdf_path, retries)
            result["metadata"] = {"split_parsing": False, "total_chunks": 1}
            return result
        else:
            # 100í˜ì´ì§€ ì´ˆê³¼: ë¶„í•  íŒŒì‹±
            logger.info(
                f"ğŸ“¡ Split parsing required ({total_pages} pages, "
                f"max {self.MAX_PAGES_PER_REQUEST} per request)"
            )
            return self._parse_pdf_in_chunks(pdf_path, total_pages, retries)

    def _get_pdf_page_count(self, pdf_path: str) -> int:
        """PDF í˜ì´ì§€ ìˆ˜ í™•ì¸"""
        try:
            reader = PdfReader(pdf_path)
            return len(reader.pages)
        except Exception as e:
            logger.error(f"Failed to read PDF page count: {e}")
            # í˜ì´ì§€ ìˆ˜ë¥¼ ì•Œ ìˆ˜ ì—†ìœ¼ë©´ ì¼ë‹¨ ë‹¨ì¼ íŒŒì‹± ì‹œë„
            return 0

    def _split_pdf(
        self, pdf_path: str, start_page: int, end_page: int, output_path: str
    ) -> None:
        """PDFë¥¼ íŠ¹ì • í˜ì´ì§€ ë²”ìœ„ë¡œ ë¶„í• """
        reader = PdfReader(pdf_path)
        writer = PdfWriter()

        for page_num in range(start_page, min(end_page, len(reader.pages))):
            writer.add_page(reader.pages[page_num])

        with open(output_path, "wb") as output_file:
            writer.write(output_file)

    def _parse_pdf_in_chunks(
        self, pdf_path: str, total_pages: int, retries: int
    ) -> Dict[str, Any]:
        """
        PDFë¥¼ 100í˜ì´ì§€ì”© ë¶„í• í•˜ì—¬ íŒŒì‹±

        ê° ì²­í¬ë¥¼ ë³„ë„ë¡œ íŒŒì‹±í•œ í›„ ê²°ê³¼ë¥¼ ë³‘í•©í•©ë‹ˆë‹¤.
        """
        all_elements = []
        chunk_count = 0
        page_offset = 0

        # 100í˜ì´ì§€ì”© ë¶„í• 
        for start_page in range(0, total_pages, self.MAX_PAGES_PER_REQUEST):
            end_page = min(start_page + self.MAX_PAGES_PER_REQUEST, total_pages)
            chunk_count += 1

            logger.info(
                f"ğŸ“„ Processing chunk {chunk_count}: "
                f"pages {start_page + 1}-{end_page} of {total_pages}"
            )

            # ì„ì‹œ íŒŒì¼ë¡œ PDF ë¶„í• 
            with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as temp_file:
                temp_path = temp_file.name

            try:
                self._split_pdf(pdf_path, start_page, end_page, temp_path)

                # ë¶„í• ëœ PDF íŒŒì‹±
                chunk_result = self._parse_single_pdf(temp_path, retries)

                # elements ìˆ˜ì§‘ ë° page ë²ˆí˜¸ ì¡°ì •
                for elem in chunk_result.get("elements", []):
                    # ì›ë³¸ PDFì˜ í˜ì´ì§€ ë²ˆí˜¸ë¡œ ì¡°ì •
                    elem["page"] = elem["page"] + page_offset
                    # ID ì¬ì¡°ì • (ì¤‘ë³µ ë°©ì§€)
                    elem["id"] = len(all_elements)
                    all_elements.append(elem)

                page_offset += chunk_result.get("usage", {}).get("pages", 0)

                # Rate limit ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
                if chunk_count < (total_pages // self.MAX_PAGES_PER_REQUEST + 1):
                    time.sleep(2)  # ì²­í¬ ê°„ 2ì´ˆ ëŒ€ê¸°

            finally:
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                Path(temp_path).unlink(missing_ok=True)

        logger.info(
            f"âœ… Split parsing completed: "
            f"{chunk_count} chunks, {len(all_elements)} total elements"
        )

        # ë³‘í•©ëœ ê²°ê³¼ ë°˜í™˜
        return {
            "api": "2.0",
            "model": "document-parse-250618",
            "usage": {"pages": total_pages},
            "content": {
                "html": "",  # ë¶„í•  íŒŒì‹± ì‹œ ì „ì²´ HTMLì€ ìƒëµ
                "markdown": "",
                "text": "",
            },
            "elements": all_elements,
            "metadata": {
                "split_parsing": True,
                "total_chunks": chunk_count,
                "pages_per_chunk": self.MAX_PAGES_PER_REQUEST,
            },
        }

    def _parse_single_pdf(self, pdf_path: str, retries: int = 3) -> Dict[str, Any]:
        """
        ë‹¨ì¼ PDF íŒŒì‹± (Upstage API ì§ì ‘ í˜¸ì¶œ)

        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            retries: ì¬ì‹œë„ íšŸìˆ˜

        Returns:
            API ì‘ë‹µ JSON

        Raises:
            Exception: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        headers = {"Authorization": f"Bearer {self.api_key}"}
        data = {
            "ocr": "force",
            "base64_encoding": "['table']",
            "model": "document-parse",
        }

        for attempt in range(retries):
            try:
                with open(pdf_path, "rb") as f:
                    files = {"document": f}
                    response = requests.post(
                        self.url, headers=headers, files=files, data=data, timeout=120
                    )

                if response.status_code == 200:
                    result = response.json()
                    element_count = len(result.get("elements", []))
                    pages_count = result.get("usage", {}).get("pages", 0)
                    logger.info(
                        f"âœ… API returned {element_count} elements from {pages_count} pages"
                    )
                    return result
                elif response.status_code == 429:  # Rate limit
                    if attempt < retries - 1:
                        wait_time = 2**attempt
                        logger.warning(
                            f"â³ Rate limited, waiting {wait_time}s before retry"
                        )
                        time.sleep(wait_time)
                        continue
                    else:
                        raise Exception(f"Rate limit exceeded: {response.text}")
                else:
                    raise Exception(
                        f"API call failed: {response.status_code} - {response.text}"
                    )

            except requests.exceptions.RequestException as e:
                if attempt < retries - 1:
                    logger.warning(f"Request failed, retrying: {e}")
                    time.sleep(2**attempt)
                    continue
                else:
                    raise Exception(f"API request failed after {retries} retries: {e}")

        raise Exception("API call failed after all retries")
